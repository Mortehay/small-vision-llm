volumes:
  hf_models:
services:
  stream-cam:
    container_name: stream-cam
    image: jrottenberg/ffmpeg
    network_mode: "host" 
    user: root
    privileged: true 
    volumes:
      - /dev:/dev
    devices:
      - /dev/video0:/dev/video0
    environment:
      - FRAME_RESOLUTION=${FRAME_RESOLUTION}
      - FRAME_RESOLUTION_CROP=${FRAME_RESOLUTION_CROP}
    entrypoint: >
      ffmpeg -f v4l2 -input_format mjpeg -framerate 30 -video_size ${FRAME_RESOLUTION} -i /dev/video0 
      -vf "crop=${FRAME_RESOLUTION_CROP}"
      -vcodec libx264 -pix_fmt yuv420p -preset ultrafast -tune zerolatency 
      -x264-params "repeat-headers=1:keyint=15" 
      -bsf:v "dump_extra=freq=keyframe" 
      -f mpegts "udp://127.0.0.1:55080?pkt_size=1316"

  # --- SmolVLM API (Fastest for CPU) ---
  vlm-smol-api:
    image: ghcr.io/huggingface/text-generation-inference:latest
    container_name: vlm_smol_api
    volumes:
      - ./models:/data  # TGI expects models in /data
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - CUDA_VISIBLE_DEVICES=""
      - VLLM_TARGET_DEVICE=openvino
    ports:
      - "48000:80"
    command: >
      --model-id HuggingFaceTB/SmolVLM2-500M-Video-Instruct
      --max-total-tokens 1024
      --trust-remote-code

  # --- Moondream API (TGI CPU) ---
  vlm-moon-api:
    image: ghcr.io/huggingface/text-generation-inference:latest
    container_name: vlm_moon_api
    volumes:
      - ./models:/data
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - CUDA_VISIBLE_DEVICES=""
      - VLLM_TARGET_DEVICE=openvino
    ports:
      - "48001:80"
    command: >
      --model-id vikhyatk/moondream2
      --max-total-tokens 1024
      --trust-remote-code

  # --- Qwen2-VL API (TGI CPU) ---
  vlm-qwen-api:
    image: ghcr.io/huggingface/text-generation-inference:latest
    container_name: vlm_qwen_api
    volumes:
      - ./models:/data
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - CUDA_VISIBLE_DEVICES=""
      - VLLM_TARGET_DEVICE=openvino
    ports:
      - "48002:80"
    command: >
      --model-id Qwen/Qwen2-VL-2B-Instruct
      --max-total-tokens 1024
      --trust-remote-code

  stream-operations:
    build:
      context: .
      dockerfile: configs/stream-operations/Dockerfile
    container_name: stream_operations
    user: root
    network_mode: "host"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - CAMERA_URL=${CAMERA_URL}
      - FRAME_RESOLUTION=${FRAME_RESOLUTION}
      - FRAME_RESOLUTION_CROPED=${FRAME_RESOLUTION_CROPED}
      - HSA_OVERRIDE_GFX_VERSION=10.3.0
      - SMOL_API_URL=http://127.0.0.1:48000/v1/chat/completions
      - MOON_API_URL=http://127.0.0.1:48001/v1/chat/completions
      - QWEN_API_URL=http://127.0.0.1:48002/v1/chat/completions

    volumes:
      - /dev:/dev
      - ./scripts:/app/scripts
      - ./logs:/app/logs
      - ./entrypoint.sh:/app/entrypoint.sh
      - ./models:/root/.cache/huggingface
    # Pass the specific script name as an argument
    entrypoint: ["tail", "-f", "/dev/null"]

